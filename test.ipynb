{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32a9d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "debbc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 설정값 ----------\n",
    "TRAIN_COUNT = 600         # 처음엔 작게! (느리면 더 줄이세요)\n",
    "TEST_COUNT  = 200\n",
    "CHANNELS    = 4           # 처음엔 4, OK면 8로\n",
    "EPOCHS      = 3\n",
    "BATCH_TRAIN = 128\n",
    "BATCH_TEST  = 256\n",
    "MAX_QNODE_BATCH = 64      # 내부 루프 분할 크기 (메모리/속도 트레이드오프)\n",
    "USE_LIGHTNING = True      # 설치했다면 True (빠름)\n",
    "CACHE_DIR   = \"./quanv_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad21be0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Backend] lightning.qubit\n"
     ]
    }
   ],
   "source": [
    "def make_device(use_lightning=True, wires=4):\n",
    "    if use_lightning:\n",
    "        try:\n",
    "            # 설치/호환 OK면 lightning 사용\n",
    "            dev = qml.device(\"lightning.qubit\", wires=wires)\n",
    "            print(\"[Backend] lightning.qubit\")\n",
    "            return dev\n",
    "        except Exception as e:\n",
    "            print(f\"[Backend] lightning.qubit 사용 불가 → default.qubit로 대체 ({e})\")\n",
    "    # 기본 백엔드\n",
    "    dev = qml.device(\"default.qubit\", wires=wires)\n",
    "    print(\"[Backend] default.qubit\")\n",
    "    return dev\n",
    "\n",
    "DEV = make_device(use_lightning=USE_LIGHTNING, wires=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3773e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_10x10(train_count=TRAIN_COUNT, test_count=TEST_COUNT):\n",
    "    tfm = transforms.Compose([transforms.ToTensor(), transforms.Resize((10,10))])\n",
    "    train_ds = datasets.MNIST(root=\"./data\", train=True,  download=True, transform=tfm)\n",
    "    test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=tfm)\n",
    "    x_train = torch.stack([train_ds[i][0] for i in range(train_count)])  # (N,1,10,10)\n",
    "    y_train = torch.tensor([train_ds[i][1] for i in range(train_count)])\n",
    "    x_test  = torch.stack([test_ds[i][0]  for i in range(test_count)])\n",
    "    y_test  = torch.tensor([test_ds[i][1] for i in range(test_count)])\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "691127f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weights(seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # 각 큐빗에 (RZ, RX) 두 개의 각도\n",
    "    return np.array(rng.uniform(0, 2*np.pi, size=(4,2)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96f35983",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(DEV, interface=\"torch\")\n",
    "def patch_qnode(pix4, weights):\n",
    "    # 데이터 인코딩\n",
    "    for w in range(4):\n",
    "        qml.RX(np.pi * pix4[w], wires=w)\n",
    "    # 얽힘\n",
    "    qml.CZ(wires=[0,1]); qml.CZ(wires=[2,3]); qml.CZ(wires=[0,2]); qml.CZ(wires=[1,3])\n",
    "    # 랜덤 단일 큐빗 회전\n",
    "    for w in range(4):\n",
    "        qml.RZ(weights[w,0], wires=w)\n",
    "        qml.RX(weights[w,1], wires=w)\n",
    "    # ⬇️ 중요한 포인트: 명시적으로 4개 스칼라를 \"튜플\"로 반환\n",
    "    return (\n",
    "        qml.expval(qml.PauliZ(0)),\n",
    "        qml.expval(qml.PauliZ(1)),\n",
    "        qml.expval(qml.PauliZ(2)),\n",
    "        qml.expval(qml.PauliZ(3)),\n",
    "    )\n",
    "\n",
    "WEIGHTS = [torch.tensor(random_weights(1000+c), dtype=torch.float32) for c in range(CHANNELS)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad9001d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 패치 추출 & Quanvolution ----------\n",
    "def extract_patches_2x2_stride2(x):  # x: (N,1,10,10)\n",
    "    N = x.shape[0]\n",
    "    patches = torch.zeros((N,5,5,4), dtype=torch.float32)\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            patch = x[:, :, 2*i:2*i+2, 2*j:2*j+2].reshape(N, 4)\n",
    "            patches[:, i, j, :] = patch\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "497e3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def quanv_transform(x, channels=CHANNELS, max_batches=MAX_QNODE_BATCH, cache_key=None):\n",
    "    # 캐시 사용\n",
    "    if cache_key is not None:\n",
    "        fpath = os.path.join(CACHE_DIR, cache_key)\n",
    "        if os.path.isfile(fpath):\n",
    "            npz = np.load(fpath)\n",
    "            return torch.tensor(npz[\"feat\"]), torch.tensor(npz[\"label\"]) if \"label\" in npz else None\n",
    "\n",
    "    patches = extract_patches_2x2_stride2(x)  # (N,5,5,4)\n",
    "    N = patches.shape[0]\n",
    "    feats = torch.zeros((N,5,5,channels), dtype=torch.float32)\n",
    "\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            p = patches[:, i, j, :]  # (N,4)\n",
    "            # 채널별\n",
    "            for ch in range(channels):\n",
    "                out_chunks = []\n",
    "                # 배치 분할\n",
    "                for s in range(0, N, max_batches):\n",
    "                    batch = p[s:s+max_batches]\n",
    "                    vals = []\n",
    "                    for b in batch:\n",
    "                        expvals = patch_qnode(b, WEIGHTS[ch])  # expvals: tuple of 4 scalars\n",
    "                        # ⬇️ 튜플/리스트 → 텐서로\n",
    "                        if isinstance(expvals, (list, tuple)):\n",
    "                            expvals = torch.stack(expvals)     # shape: (4,)\n",
    "                        else:\n",
    "                            expvals = torch.as_tensor(expvals) # 혹시 모를 타입 섞임 방지\n",
    "\n",
    "                        vals.append(expvals.mean().unsqueeze(0))  # (1,)\n",
    "                    out_chunks.append(torch.cat(vals, dim=0))\n",
    "                feats[:, i, j, ch] = torch.cat(out_chunks, dim=0)\n",
    "\n",
    "    if cache_key is not None:\n",
    "        np.savez_compressed(os.path.join(CACHE_DIR, cache_key), feat=feats.numpy())\n",
    "    return feats, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "296ec2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 분류기 ----------\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, channels=CHANNELS):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5*5*channels, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    def forward(self, x):  # x: (N,5,5,C)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval(); correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            logits = model(xb)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += (pred == yb).sum().item()\n",
    "            total += yb.numel()\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64f5b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 1) 데이터 로드\n",
    "    (x_train, y_train), (x_test, y_test) = load_mnist_10x10()\n",
    "    print(\"data:\", x_train.shape, x_test.shape)\n",
    "\n",
    "    # 2) Quanvolution 특징 생성 (캐시 사용)\n",
    "    train_key = f\"train_feat_C{CHANNELS}_N{TRAIN_COUNT}.npz\"\n",
    "    test_key  = f\"test_feat_C{CHANNELS}_N{TEST_COUNT}.npz\"\n",
    "    x_train_feat, _ = quanv_transform(x_train, channels=CHANNELS, cache_key=train_key)\n",
    "    x_test_feat,  _ = quanv_transform(x_test,  channels=CHANNELS, cache_key=test_key)\n",
    "    print(\"features:\", x_train_feat.shape, x_test_feat.shape)  # (N,5,5,C)\n",
    "\n",
    "    # 3) 학습/평가\n",
    "    clf = Classifier(CHANNELS)\n",
    "    opt = torch.optim.Adam(clf.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(x_train_feat, y_train), batch_size=BATCH_TRAIN, shuffle=True)\n",
    "    test_loader  = DataLoader(TensorDataset(x_test_feat,  y_test),  batch_size=BATCH_TEST)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        clf.train()\n",
    "        for xb, yb in train_loader:\n",
    "            opt.zero_grad()\n",
    "            logits = clf(xb)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        acc = evaluate(clf, test_loader)\n",
    "        print(f\"[epoch {epoch+1}] test_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99f42554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: torch.Size([600, 1, 10, 10]) torch.Size([200, 1, 10, 10])\n",
      "features: torch.Size([600, 5, 5, 4]) torch.Size([200, 5, 5, 4])\n",
      "[epoch 1] test_acc = 0.1850\n",
      "[epoch 2] test_acc = 0.1850\n",
      "[epoch 3] test_acc = 0.1900\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bf8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
